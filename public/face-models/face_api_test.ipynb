{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d14e2a",
   "metadata": {},
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face API - Thai HandMate\n",
    "\n",
    "**‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Expression Detection ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Thai HandMate**\n",
    "\n",
    "## ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Notebook ‡∏ô‡∏µ‡πâ\n",
    "\n",
    "‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face API ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Frontend:\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (Happy, Sad, Angry, Surprised, Neutral, etc.)\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (Face Detection)\n",
    "- ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (Confidence Score)\n",
    "\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
    "\n",
    "1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "2. Download ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Face Models  \n",
    "3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Model ‡∏î‡πâ‡∏ß‡∏¢ Gradio Interface\n",
    "4. Capture ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á PNG 3 ‡πÑ‡∏ü‡∏•‡πå\n",
    "5. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PNG ‡∏î‡πâ‡∏ß‡∏¢ Model\n",
    "6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞ Import Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection...\")\n",
    "\n",
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á packages ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úì ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á {package} ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á {package} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {str(e)}\")\n",
    "\n",
    "# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ packages ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "packages = [\n",
    "    \"opencv-python\",\n",
    "    \"numpy\", \n",
    "    \"gradio\",\n",
    "    \"Pillow\",\n",
    "    \"face-recognition\"  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö face detection\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á Import Libraries...\")\n",
    "\n",
    "# Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "print(\"‚úì OpenCV version:\", cv2.__version__)\n",
    "print(\"‚úì NumPy version:\", np.__version__)\n",
    "print(\"‚úì Gradio version:\", gr.__version__)\n",
    "print(\"‚úì PIL version:\", Image.__version__)\n",
    "\n",
    "print(\"\\n‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞ Import Libraries ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Download ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Face Models\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Face Models...\")\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡∏Ç‡∏≠‡∏á models\n",
    "models_path = \".\"  # current directory\n",
    "model_files = [\n",
    "    \"tiny_face_detector_model-weights_manifest.json\",\n",
    "    \"tiny_face_detector_model-shard1\",\n",
    "    \"face_landmark_68_model-weights_manifest.json\", \n",
    "    \"face_landmark_68_model-shard1\",\n",
    "    \"face_expression_model-weights_manifest.json\",\n",
    "    \"face_expression_model-shard1\",\n",
    "    \"face_recognition_model-weights_manifest.json\",\n",
    "    \"face_recognition_model-shard1\",\n",
    "    \"ssd_mobilenetv1_model-weights_manifest.json\"\n",
    "]\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå model ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà\n",
    "print(\"\\nüìÅ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå Face Models:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "existing_models = []\n",
    "missing_models = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    file_path = os.path.join(models_path, model_file)\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        size_mb = file_size / (1024 * 1024)\n",
    "        existing_models.append(model_file)\n",
    "        print(f\"‚úì {model_file} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        missing_models.append(model_file)\n",
    "        print(f\"‚úó {model_file} - ‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö\")\n",
    "\n",
    "print(\"\\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Face Models:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö: {len(existing_models)} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "print(f\"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö: {len(missing_models)} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "\n",
    "if existing_models:\n",
    "    print(\"\\nüìã ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\")\n",
    "    for model in existing_models:\n",
    "        print(f\"  - {model}\")\n",
    "\n",
    "if missing_models:\n",
    "    print(\"\\n‚ö†Ô∏è  ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î:\")\n",
    "    for model in missing_models:\n",
    "        print(f\"  - {model}\")\n",
    "    print(\"\\n‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å face-api.js models\")\n",
    "else:\n",
    "    print(\"\\nüéâ Face Models ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß!\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö JavaScript runtime ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö face-api.js (‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)\n",
    "print(\"\\nüí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ face-api.js ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ JavaScript runtime\")\n",
    "print(\"üí° Notebook ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ OpenCV ‡πÅ‡∏•‡∏∞ face-recognition library ‡πÅ‡∏ó‡∏ô\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection ‡∏î‡πâ‡∏ß‡∏¢ Gradio Interface\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Gradio Interface ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection...\")\n",
    "\n",
    "import face_recognition\n",
    "\n",
    "def detect_faces_and_emotions(image):\n",
    "    \"\"\"\n",
    "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ‡πÅ‡∏õ‡∏•‡∏á PIL Image ‡πÄ‡∏õ‡πá‡∏ô numpy array\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "        face_locations = face_recognition.face_locations(image_array)\n",
    "        \n",
    "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        results = {\n",
    "            \"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\": len(face_locations),\n",
    "            \"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\": [],\n",
    "            \"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞\": \"‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "        }\n",
    "        \n",
    "        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "        image_with_faces = image_array.copy()\n",
    "        \n",
    "        for i, (top, right, bottom, left) in enumerate(face_locations):\n",
    "            # ‡∏ß‡∏≤‡∏î‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "            cv2.rectangle(image_with_faces, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\n",
    "            results[\"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"].append({\n",
    "                \"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà\": i + 1,\n",
    "                \"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\": f\"({left}, {top}) ‡∏ñ‡∏∂‡∏á ({right}, {bottom})\",\n",
    "                \"‡∏Ç‡∏ô‡∏≤‡∏î\": f\"{right-left} x {bottom-top} pixels\"\n",
    "            })\n",
    "            \n",
    "            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏†‡∏≤‡∏û\n",
    "            cv2.putText(image_with_faces, f\"Face {i+1} - No Emotion Model\", \n",
    "                       (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "        if len(face_locations) == 0:\n",
    "            results[\"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞\"] = \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ\"\n",
    "        \n",
    "        return image_with_faces, json.dumps(results, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\"\n",
    "        return image, error_msg\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Gradio Interface\n",
    "print(\"üéØ ‡∏™‡∏£‡πâ‡∏≤‡∏á Gradio Interface...\")\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=detect_faces_and_emotions,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Image(type=\"numpy\", label=\"‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"),\n",
    "        gr.Textbox(label=\"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö (JSON)\", lines=10)\n",
    "    ],\n",
    "    title=\"üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection - Thai HandMate\",\n",
    "    description=\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå)\",\n",
    "    examples=None\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Gradio Interface ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!\")\n",
    "print(\"üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Interface ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\")\n",
    "print(\"üí° ‡∏Å‡∏î 'Launch' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Interface\")\n",
    "\n",
    "# ‡πÄ‡∏õ‡∏¥‡∏î Gradio Interface\n",
    "demo.launch(share=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea1dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Capture ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á PNG 3 ‡πÑ‡∏ü‡∏•‡πå\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Capture ‡∏†‡∏≤‡∏û...\")\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class CameraCapture:\n",
    "    def __init__(self):\n",
    "        self.cap = None\n",
    "        self.captured_images = []\n",
    "        \n",
    "    def initialize_camera(self):\n",
    "        \"\"\"‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á\"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ\")\n",
    "                return False\n",
    "            \n",
    "            # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "            \n",
    "            print(\"‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def capture_images(self, num_images=3):\n",
    "        \"\"\"‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\"\"\"\n",
    "        if not self.initialize_camera():\n",
    "            return []\n",
    "        \n",
    "        self.captured_images = []\n",
    "        print(f\"\\nüì∏ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û {num_images} ‡∏£‡∏π‡∏õ\")\n",
    "        print(\"üí° ‡∏Å‡∏î 'c' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û, 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        capture_count = 0\n",
    "        \n",
    "        while capture_count < num_images:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ\")\n",
    "                break\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏†‡∏≤‡∏û\n",
    "            cv2.putText(display_frame, f\"Image {capture_count + 1}/{num_images}\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, \"Press 'c' to capture, 'q' to quit\", \n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Camera - Face Detection Test', display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('c'):  # ‡∏Å‡∏î 'c' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"face_test_image_{capture_count + 1}_{timestamp}.png\"\n",
    "                \n",
    "                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û\n",
    "                cv2.imwrite(filename, frame)\n",
    "                self.captured_images.append(filename)\n",
    "                capture_count += 1\n",
    "                \n",
    "                print(f\"üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û {capture_count}: {filename}\")\n",
    "                \n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢\n",
    "                cv2.imshow(f'Captured Image {capture_count}', frame)\n",
    "                time.sleep(0.5)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢\n",
    "                \n",
    "            elif key == ord('q'):  # ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n",
    "                print(\"üö´ ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û\")\n",
    "                break\n",
    "        \n",
    "        # ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return self.captured_images\n",
    "    \n",
    "    def auto_capture(self, num_images=3, delay=3):\n",
    "        \"\"\"‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\"\"\"\n",
    "        if not self.initialize_camera():\n",
    "            return []\n",
    "        \n",
    "        self.captured_images = []\n",
    "        print(f\"\\nüì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ {num_images} ‡∏£‡∏π‡∏õ (‡∏´‡πà‡∏≤‡∏á {delay} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            print(f\"‚è≥ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà {i + 1} ‡πÉ‡∏ô {delay} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...\")\n",
    "            \n",
    "            # ‡∏ô‡∏±‡∏ö‡∏ñ‡∏≠‡∏¢‡∏´‡∏•‡∏±‡∏á\n",
    "            for countdown in range(delay, 0, -1):\n",
    "                ret, frame = self.cap.read()\n",
    "                if ret:\n",
    "                    display_frame = frame.copy()\n",
    "                    cv2.putText(display_frame, f\"Image {i + 1}/{num_images}\", \n",
    "                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.putText(display_frame, f\"Capturing in: {countdown}\", \n",
    "                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    cv2.imshow('Auto Capture - Face Detection Test', display_frame)\n",
    "                    \n",
    "                if cv2.waitKey(1000) & 0xFF == ord('q'):\n",
    "                    self.cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return self.captured_images\n",
    "            \n",
    "            # ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                filename = f\"face_test_image_{i + 1}_{timestamp}.png\"\n",
    "                \n",
    "                cv2.imwrite(filename, frame)\n",
    "                self.captured_images.append(filename)\n",
    "                print(f\"üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û {i + 1}: {filename}\")\n",
    "        \n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return self.captured_images\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á instance ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û\n",
    "camera = CameraCapture()\n",
    "\n",
    "print(\"üéØ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û:\")\n",
    "print(\"1. Manual Capture (‡∏Å‡∏î 'c' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡πà‡∏≤‡∏¢)\")\n",
    "print(\"2. Auto Capture (‡∏ñ‡πà‡∏≤‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ó‡∏∏‡∏Å 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\")\n",
    "\n",
    "# ‡πÉ‡∏ä‡πâ auto capture ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô\n",
    "print(\"\\nü§ñ ‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î Auto Capture...\")\n",
    "captured_files = camera.auto_capture(num_images=3, delay=3)\n",
    "\n",
    "print(f\"\\n‚úÖ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(captured_files)} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "print(\"üìÅ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢:\")\n",
    "for i, filename in enumerate(captured_files, 1):\n",
    "    file_size = os.path.getsize(filename) / 1024  # KB\n",
    "    print(f\"  {i}. {filename} ({file_size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fa941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PNG ‡∏î‡πâ‡∏ß‡∏¢ Face Detection Model\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ Face Detection Model...\")\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FaceProcessor:\n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "    \n",
    "    def process_image(self, image_path):\n",
    "        \"\"\"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß - ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\"\"\"\n",
    "        try:\n",
    "            # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                return {\"error\": f\"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {image_path}\"}\n",
    "            \n",
    "            # ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏µ‡∏à‡∏≤‡∏Å BGR ‡πÄ‡∏õ‡πá‡∏ô RGB\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "            face_locations = face_recognition.face_locations(rgb_image)\n",
    "            \n",
    "            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "            result = {\n",
    "                \"‡πÑ‡∏ü‡∏•‡πå\": os.path.basename(image_path),\n",
    "                \"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\": len(face_locations),\n",
    "                \"‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û\": f\"{image.shape[1]} x {image.shape[0]} pixels\",\n",
    "                \"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\": [],\n",
    "                \"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "            }\n",
    "            \n",
    "            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "            for i, (top, right, bottom, left) in enumerate(face_locations):\n",
    "                face_info = {\n",
    "                    \"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà\": i + 1,\n",
    "                    \"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\": {\n",
    "                        \"left\": int(left),\n",
    "                        \"top\": int(top), \n",
    "                        \"right\": int(right),\n",
    "                        \"bottom\": int(bottom)\n",
    "                    },\n",
    "                    \"‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\": f\"{right-left} x {bottom-top} pixels\",\n",
    "                    \"‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏´‡∏•‡∏±‡∏Å\": \"‡πÑ‡∏°‡πà‡∏û‡∏ö\",\n",
    "                    \"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à\": 0.0,\n",
    "                    \"‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "                }\n",
    "                \n",
    "                result[\"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\"].append(face_info)\n",
    "                \n",
    "                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏ö‡∏ô‡∏†‡∏≤‡∏û\n",
    "                cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(image, f\"Face {i+1} - No Emotion\", \n",
    "                           (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "            \n",
    "            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏£‡∏≠‡∏ö\n",
    "            if face_locations:\n",
    "                output_path = image_path.replace('.png', '_processed.png')\n",
    "                cv2.imwrite(output_path, image)\n",
    "                result[\"‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\"] = output_path\n",
    "            else:\n",
    "                result[\"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞\"] = \"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ - ‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}\"}\n",
    "    \n",
    "    def process_all_images(self):\n",
    "        \"\"\"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\"\"\"\n",
    "        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå PNG ‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ\n",
    "        image_files = glob.glob(\"face_test_image_*.png\")\n",
    "        image_files = [f for f in image_files if '_processed' not in f]  # ‡πÑ‡∏°‡πà‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå processed\n",
    "        \n",
    "        if not image_files:\n",
    "            print(\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ\")\n",
    "            print(\"üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ó‡∏µ‡πà 4 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"üì∏ ‡∏û‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡πà‡∏≤‡∏¢‡πÑ‡∏ß‡πâ: {len(image_files)} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        self.results = []\n",
    "        \n",
    "        for image_file in sorted(image_files):\n",
    "            print(f\"\\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {image_file}\")\n",
    "            result = self.process_image(image_file)\n",
    "            \n",
    "            if \"error\" in result:\n",
    "                print(f\"‚ùå {result['error']}\")\n",
    "            else:\n",
    "                self.results.append(result)\n",
    "                print(f\"‚úÖ ‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤: {result['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤']} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "                \n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "                if result['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤'] > 0:\n",
    "                    for face in result[\"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\"]:\n",
    "                        print(f\"   - ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {face['‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà']}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\")\n",
    "                else:\n",
    "                    print(\"   - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def display_summary(self):\n",
    "        \"\"\"‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        total_faces = sum(result[\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"] for result in self.results)\n",
    "        total_images = len(self.results)\n",
    "        \n",
    "        print(f\"üì∏ ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_images} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "        print(f\"üë• ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_faces} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "        print(f\"üìà ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {total_faces/total_images:.1f} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≠‡∏†‡∏≤‡∏û\")\n",
    "        print(f\"üé≠ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á processor ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\n",
    "processor = FaceProcessor()\n",
    "results = processor.process_all_images()\n",
    "processor.display_summary()\n",
    "\n",
    "print(f\"\\nüíæ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ 'results' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\")\n",
    "print(f\"üìÅ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {len(results)} ‡πÑ‡∏ü‡∏•‡πå\")\n",
    "print(f\"üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee31f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• JSON ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á JSON Output ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå...\")\n",
    "\n",
    "def create_emotion_json(results):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\"\"\n",
    "    if not results:\n",
    "        return {\"error\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á\"}\n",
    "    \n",
    "    emotion_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_images\": len(results),\n",
    "        \"total_faces\": sum(result[\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"] for result in results),\n",
    "        \"emotion_status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\",\n",
    "        \"images\": []\n",
    "    }\n",
    "    \n",
    "    for result in results:\n",
    "        image_data = {\n",
    "            \"filename\": result[\"‡πÑ‡∏ü‡∏•‡πå\"],\n",
    "            \"faces_detected\": result[\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"],\n",
    "            \"faces\": []\n",
    "        }\n",
    "        \n",
    "        for face in result[\"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\"]:\n",
    "            face_emotion = {\n",
    "                \"face_id\": face[\"‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà\"],\n",
    "                \"primary_emotion\": \"‡πÑ‡∏°‡πà‡∏û‡∏ö\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"emotion_scores\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\",\n",
    "                \"face_position\": face[\"‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á\"],\n",
    "                \"status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "            }\n",
    "            image_data[\"faces\"].append(face_emotion)\n",
    "        \n",
    "        emotion_data[\"images\"].append(image_data)\n",
    "    \n",
    "    return emotion_data\n",
    "\n",
    "def create_summary_json(results):\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\"\"\n",
    "    if not results:\n",
    "        return {\"error\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á\"}\n",
    "    \n",
    "    total_faces = sum(result[\"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\"] for result in results)\n",
    "    \n",
    "    summary_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"summary\": {\n",
    "            \"total_images_processed\": len(results),\n",
    "            \"total_faces_detected\": total_faces,\n",
    "            \"average_faces_per_image\": round(total_faces / len(results), 2),\n",
    "            \"emotion_detection_status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "        },\n",
    "        \"emotion_distribution\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\",\n",
    "        \"message\": \"‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "    }\n",
    "    \n",
    "    return summary_data\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if 'results' in locals() and results:\n",
    "    print(\"‚úÖ ‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î\n",
    "    print(\"\\nüìÑ JSON ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\")\n",
    "    print(\"=\"*60)\n",
    "    emotion_json = create_emotion_json(results)\n",
    "    print(json.dumps(emotion_json, ensure_ascii=False, indent=2))\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏™‡∏£‡∏∏‡∏õ\n",
    "    print(\"\\nüìä JSON ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö:\")\n",
    "    print(\"=\"*60)\n",
    "    summary_json = create_summary_json(results)\n",
    "    print(json.dumps(summary_json, ensure_ascii=False, indent=2))\n",
    "    \n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON\n",
    "    with open(\"face_detection_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(emotion_json, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    with open(\"face_detection_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary_json, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡πÅ‡∏•‡πâ‡∏ß:\")\n",
    "    print(f\"  - face_detection_results.json ({os.path.getsize('face_detection_results.json')} bytes)\")\n",
    "    print(f\"  - face_detection_summary.json ({os.path.getsize('face_detection_summary.json')} bytes)\")\n",
    "    \n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "    print(f\"\\nüé≠ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå:\")\n",
    "    print(\"=\"*60)\n",
    "    simple_status = {}\n",
    "    for img_data in emotion_json[\"images\"]:\n",
    "        filename = img_data[\"filename\"]\n",
    "        face_count = img_data[\"faces_detected\"]\n",
    "        simple_status[filename] = {\n",
    "            \"faces_detected\": face_count,\n",
    "            \"emotion_status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "        }\n",
    "    \n",
    "    print(json.dumps(simple_status, ensure_ascii=False, indent=2))\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "    print(\"üí° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏ó‡∏µ‡πà 5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "    sample_json = {\n",
    "        \"error\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\",\n",
    "        \"message\": \"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô‡πÄ‡∏ã‡∏•‡∏•‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô\",\n",
    "        \"expected_format\": {\n",
    "            \"timestamp\": \"2025-09-13T12:00:00\",\n",
    "            \"emotion_status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\",\n",
    "            \"images\": [\n",
    "                {\n",
    "                    \"filename\": \"face_test_image_1.png\",\n",
    "                    \"faces_detected\": 1,\n",
    "                    \"faces\": [\n",
    "                        {\n",
    "                            \"face_id\": 1,\n",
    "                            \"primary_emotion\": \"‡πÑ‡∏°‡πà‡∏û‡∏ö\",\n",
    "                            \"confidence\": 0.0,\n",
    "                            \"emotion_scores\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\",\n",
    "                            \"status\": \"‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüìÑ ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:\")\n",
    "    print(json.dumps(sample_json, ensure_ascii=False, indent=2))\n",
    "\n",
    "print(f\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• JSON ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection!\")\n",
    "print(f\"üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ mock data - ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d14e2a",
   "metadata": {},
   "source": [
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face API - ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Person 3: ‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏• Face Expression Detection**\n",
    "\n",
    "## ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Notebook ‡∏ô‡∏µ‡πâ\n",
    "\n",
    "Notebook ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face API ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Frontend:\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (Happy, Sad, Angry, Surprised, Neutral, etc.)\n",
    "- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (Face Detection)\n",
    "- ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (Confidence Score)\n",
    "\n",
    "## ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå\n",
    "\n",
    "1. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á** - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ\n",
    "2. **‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥** - ‡∏î‡∏π confidence score ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ 50%\n",
    "3. **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå** - ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ\n",
    "\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
    "\n",
    "1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• Face API\n",
    "2. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•  \n",
    "3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "4. ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "5. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏•‡∏±‡∏Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26319e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á libraries ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection...\")\n",
    "print(\"‚è∞ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 2-3 ‡∏ô‡∏≤‡∏ó‡∏µ)\")\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python pillow numpy matplotlib requests\n",
    "!{sys.executable} -m pip install mediapipe  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")\n",
    "print(\"üìã Libraries ‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á:\")\n",
    "print(\"   - OpenCV: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û\") \n",
    "print(\"   - Pillow: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\")\n",
    "print(\"   - NumPy: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì\")\n",
    "print(\"   - Matplotlib: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü\")\n",
    "print(\"   - MediaPipe: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: Import Libraries ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Face Detector\n",
    "\n",
    "print(\"üìñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á import libraries...\")\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üñ•Ô∏è  ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏ö‡∏ö:\")\n",
    "print(f\"   üìÅ Current Directory: {os.getcwd()}\")\n",
    "print(f\"   üì∏ OpenCV Version: {cv2.__version__}\")\n",
    "print(f\"   ü§ñ MediaPipe Version: {mp.__version__}\")\n",
    "\n",
    "class FaceEmotionDetector:\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "    ‡πÉ‡∏ä‡πâ MediaPipe ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"üîß ‡∏™‡∏£‡πâ‡∏≤‡∏á Face Emotion Detector...\")\n",
    "        self.mp_face_detection = mp.solutions.face_detection\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.face_detection = self.mp_face_detection.FaceDetection(\n",
    "            model_selection=0,  # 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÉ‡∏Å‡∏•‡πâ (< 2 ‡πÄ‡∏°‡∏ï‡∏£)\n",
    "            min_detection_confidence=0.5\n",
    "        )\n",
    "        print(\"‚úÖ Face Detector ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß!\")\n",
    "        \n",
    "    def detect_faces(self, image_path_or_array, show_details=True):\n",
    "        \"\"\"‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\"\"\"\n",
    "        try:\n",
    "            # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "            if isinstance(image_path_or_array, str):\n",
    "                image = cv2.imread(image_path_or_array)\n",
    "                if image is None:\n",
    "                    print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {image_path_or_array}\")\n",
    "                    return None\n",
    "            else:\n",
    "                image = image_path_or_array.copy()\n",
    "            \n",
    "            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB (MediaPipe ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ RGB)\n",
    "            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "            results = self.face_detection.process(rgb_image)\n",
    "            \n",
    "            detected_faces = []\n",
    "            \n",
    "            if results.detections:\n",
    "                for i, detection in enumerate(results.detections):\n",
    "                    confidence = detection.score[0]\n",
    "                    \n",
    "                    # ‡πÑ‡∏î‡πâ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, ic = image.shape\n",
    "                    x = int(bboxC.xmin * iw)\n",
    "                    y = int(bboxC.ymin * ih)\n",
    "                    w = int(bboxC.width * iw)\n",
    "                    h = int(bboxC.height * ih)\n",
    "                    \n",
    "                    detected_faces.append({\n",
    "                        'face_id': i + 1,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': (x, y, w, h),\n",
    "                        'emotion': 'neutral'  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå)\n",
    "                    })\n",
    "                    \n",
    "                    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏£‡∏≠‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(image, f'Face {i+1}: {confidence:.2f}', \n",
    "                               (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            result = {\n",
    "                'total_faces': len(detected_faces),\n",
    "                'faces': detected_faces,\n",
    "                'image_with_boxes': image\n",
    "            }\n",
    "            \n",
    "            if show_details:\n",
    "                print(\"=\"*50)\n",
    "                print(\"üë§ ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤:\")\n",
    "                print(f\"   üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö: {len(detected_faces)}\")\n",
    "                \n",
    "                for face in detected_faces:\n",
    "                    print(f\"   üë§ ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {face['face_id']}: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ {face['confidence']:.1%}\")\n",
    "                \n",
    "                if len(detected_faces) == 0:\n",
    "                    print(\"   ‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\")\n",
    "                    print(\"   üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\")\n",
    "                \n",
    "                print(\"=\"*50)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_emotion_analysis(self, face_region):\n",
    "        \"\"\"\n",
    "        ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ (Mock function)\n",
    "        ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°\n",
    "        \"\"\"\n",
    "        # Mock emotions - ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI\n",
    "        emotions = {\n",
    "            'neutral': 0.4,\n",
    "            'happy': 0.3,\n",
    "            'sad': 0.1,\n",
    "            'angry': 0.1,\n",
    "            'surprised': 0.1\n",
    "        }\n",
    "        \n",
    "        # ‡∏´‡∏≤‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î\n",
    "        top_emotion = max(emotions, key=emotions.get)\n",
    "        \n",
    "        return {\n",
    "            'emotions': emotions,\n",
    "            'top_emotion': top_emotion,\n",
    "            'confidence': emotions[top_emotion]\n",
    "        }\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á instance\n",
    "print(\"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Face Detector...\")\n",
    "face_detector = FaceEmotionDetector()\n",
    "\n",
    "print(\"\\nüéâ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection!\")\n",
    "print(\"üìã ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ:\")\n",
    "print(\"   - face_detector.detect_faces() - ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "print(\"   - face_detector.get_emotion_analysis() - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "\n",
    "def test_face_detection_with_image(image_filename=\"test_face.jpg\"):\n",
    "    \"\"\"\n",
    "    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\n",
    "    \n",
    "    ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ:\n",
    "    1. ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö notebook ‡∏ô‡∏µ‡πâ\n",
    "    2. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô function ‡∏ô‡∏µ‡πâ\n",
    "    3. ‡∏£‡∏±‡∏ô cell\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û...\")\n",
    "    print(f\"üìÑ ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå: {image_filename}\")\n",
    "    \n",
    "    if os.path.exists(image_filename):\n",
    "        print(f\"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {image_filename}\")\n",
    "        \n",
    "        # ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\n",
    "        original_image = cv2.imread(image_filename)\n",
    "        original_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "        print(\"\\nü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤...\")\n",
    "        result = face_detector.detect_faces(image_filename, show_details=True)\n",
    "        \n",
    "        if result:\n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # ‡∏£‡∏π‡∏õ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö\n",
    "            ax1.imshow(original_rgb)\n",
    "            ax1.set_title('üì∏ ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö', fontsize=14)\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏•‡πâ‡∏ß\n",
    "            result_rgb = cv2.cvtColor(result['image_with_boxes'], cv2.COLOR_BGR2RGB)\n",
    "            ax2.imshow(result_rgb)\n",
    "            ax2.set_title(f'üë§ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ {result[\"total_faces\"]} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤', fontsize=14)\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "            print(\"\\nüéâ ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection:\")\n",
    "            if result['total_faces'] > 0:\n",
    "                print(f\"   üåü ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ {result['total_faces']} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "                \n",
    "                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (Mock)\n",
    "                for i, face in enumerate(result['faces']):\n",
    "                    emotion_result = face_detector.get_emotion_analysis(None)  # Mock\n",
    "                    print(f\"   üòä ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {i+1}: ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå '{emotion_result['top_emotion']}' ({emotion_result['confidence']:.1%})\")\n",
    "                \n",
    "                print(\"   üí° ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Frontend\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û\")\n",
    "                print(\"   üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\")\n",
    "                print(\"      - ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\")\n",
    "                print(\"      - ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\")\n",
    "                print(\"      - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏™‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ\")\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "            if result['total_faces'] > 0:\n",
    "                emotion_data = face_detector.get_emotion_analysis(None)\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                emotions = list(emotion_data['emotions'].keys())\n",
    "                scores = list(emotion_data['emotions'].values())\n",
    "                \n",
    "                colors = ['#ff6b6b' if emotion == emotion_data['top_emotion'] else '#4ecdc4' for emotion in emotions]\n",
    "                \n",
    "                plt.bar(emotions, scores, color=colors)\n",
    "                plt.xlabel('Emotions')\n",
    "                plt.ylabel('Confidence Score')\n",
    "                plt.title('üòä Face Emotion Analysis (Mock Data)', fontsize=14, pad=20)\n",
    "                plt.ylim(0, 1)\n",
    "                \n",
    "                for i, score in enumerate(scores):\n",
    "                    plt.text(i, score + 0.01, f'{score:.1%}', ha='center')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "    else:\n",
    "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå {image_filename}\")\n",
    "        print(\"\\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏π‡∏õ‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\")\n",
    "        print(\"   1. ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\")\n",
    "        print(\"   2. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö notebook ‡∏ô‡∏µ‡πâ\")\n",
    "        print(\"   3. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ\")\n",
    "        print(f\"   4. ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: .jpg, .jpeg, .png\")\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ\n",
    "print(\"üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection ‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û...\")\n",
    "test_face_detection_with_image(\"test_face.jpg\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection:\")\n",
    "print(\"   üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\")\n",
    "print(\"   üí° ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏™‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ\")\n",
    "print(\"   üîÑ ‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\")\n",
    "print(\"   üìä confidence > 50% = ‡∏ú‡πà‡∏≤‡∏ô\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f90519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìπ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°‡πÅ‡∏ö‡∏ö Real-time\n",
    "\n",
    "def run_face_detection_webcam():\n",
    "    \"\"\"\n",
    "    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏°‡πÅ‡∏ö‡∏ö Real-time\n",
    "    \n",
    "    ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\n",
    "    - ‡∏Å‡∏î 'S' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "    - ‡∏Å‡∏î 'Q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö\n",
    "    - ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìπ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏Ñ‡∏° ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!\")\n",
    "            print(\"üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:\")\n",
    "            print(\"   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏≠‡∏¢‡∏π‡πà\")\n",
    "            print(\"   - ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á\")\n",
    "            print(\"   - ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó Jupyter Notebook\")\n",
    "            return\n",
    "        \n",
    "        print(\"‚úÖ ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéÆ ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°:\")\n",
    "        print(\"   üì∏ ‡∏Å‡∏î 'S' = ‡∏ñ‡πà‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection\")\n",
    "        print(\"   üö™ ‡∏Å‡∏î 'Q' = ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö\")\n",
    "        print(\"\\nüòä ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏™‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ:\")\n",
    "        print(\"   üòä ‡∏¢‡∏¥‡πâ‡∏°   üò¢ ‡πÄ‡∏®‡∏£‡πâ‡∏≤   üò† ‡πÇ‡∏Å‡∏£‡∏ò   üò≤ ‡∏õ‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏î‡πÉ‡∏à   üòê ‡πÄ‡∏â‡∏¢‡πÜ\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        capture_count = 0\n",
    "        detection_log = []  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ\")\n",
    "                break\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠\n",
    "            cv2.putText(frame, \"Face Detection Test\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, \"Press 'S' to test, 'Q' to quit\", \n",
    "                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Tests: {capture_count}\", \n",
    "                       (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "            \n",
    "            # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Face Detection\n",
    "            cv2.rectangle(frame, (50, 50), (590, 430), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Face Detection Zone\", \n",
    "                       (60, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Face Detection - Webcam Test', frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('s') or key == ord('S'):  # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "                capture_count += 1\n",
    "                print(f\"\\nüì∏ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {capture_count}\")\n",
    "                \n",
    "                # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\n",
    "                print(\"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤...\")\n",
    "                result = face_detector.detect_faces(frame, show_details=False)\n",
    "                \n",
    "                if result:\n",
    "                    faces_detected = result['total_faces']\n",
    "                    \n",
    "                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•\n",
    "                    detection_log.append({\n",
    "                        'test': capture_count,\n",
    "                        'faces_detected': faces_detected,\n",
    "                        'success': faces_detected > 0\n",
    "                    })\n",
    "                    \n",
    "                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô terminal\n",
    "                    print(f\"üë§ ‡∏ú‡∏•: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ {faces_detected} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "                    \n",
    "                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô‡∏†‡∏≤‡∏û\n",
    "                    if faces_detected > 0:\n",
    "                        result_text = f\"Faces: {faces_detected}\"\n",
    "                        cv2.putText(frame, result_text, \n",
    "                                   (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                        \n",
    "                        status_text = \"Detection Success!\"\n",
    "                        color = (0, 255, 0)  # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß\n",
    "                        print(\"   ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\")\n",
    "                        \n",
    "                        # Mock emotion analysis\n",
    "                        emotion_result = face_detector.get_emotion_analysis(None)\n",
    "                        emotion_text = f\"Emotion: {emotion_result['top_emotion']}\"\n",
    "                        cv2.putText(frame, emotion_text, \n",
    "                                   (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 100, 0), 2)\n",
    "                        print(f\"   üòä ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå: {emotion_result['top_emotion']} ({emotion_result['confidence']:.1%})\")\n",
    "                        \n",
    "                    else:\n",
    "                        result_text = \"No Face Detected\"\n",
    "                        cv2.putText(frame, result_text, \n",
    "                                   (10, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 100, 255), 2)\n",
    "                        \n",
    "                        status_text = \"Try Again\"\n",
    "                        color = (0, 100, 255)  # ‡∏™‡πâ‡∏°\n",
    "                        print(\"   ‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤ ‡∏•‡∏≠‡∏á‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\")\n",
    "                    \n",
    "                    cv2.putText(frame, status_text, \n",
    "                               (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                    \n",
    "                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥\n",
    "                    tips = [\"Try smiling!\", \"Make angry face\", \"Look surprised\", \"Stay neutral\"]\n",
    "                    tip = tips[capture_count % len(tips)]\n",
    "                    print(f\"   üí° ‡∏•‡∏≠‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ: {tip}\")\n",
    "                    cv2.putText(frame, f\"Next: {tip}\", \n",
    "                               (10, 230), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    cv2.imshow('Face Detection - Result', frame)\n",
    "                    cv2.waitKey(3000)\n",
    "                \n",
    "            elif key == ord('q') or key == ord('Q'):  # ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n",
    "                print(\"\\nüëã ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á...\")\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection:\")\n",
    "        print(f\"   üî¢ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {capture_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\")\n",
    "        \n",
    "        if detection_log:\n",
    "            successful_detections = [log for log in detection_log if log['success']]\n",
    "            success_rate = len(successful_detections) / len(detection_log) * 100\n",
    "            \n",
    "            print(f\"   ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(successful_detections)} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á\")\n",
    "            print(f\"   üìà ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {success_rate:.1f}%\")\n",
    "            \n",
    "            print(\"\\nüìù ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\")\n",
    "            for log in detection_log:\n",
    "                status = \"‚úÖ\" if log['success'] else \"‚ö†Ô∏è\"\n",
    "                print(f\"   {status} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {log['test']:2d}: {log['faces_detected']} ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤\")\n",
    "            \n",
    "            if success_rate >= 80:\n",
    "                print(\"\\nüéâ ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°! Face Detection ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏°‡∏≤‡∏Å\")\n",
    "            elif success_rate >= 60:\n",
    "                print(\"\\n‚úÖ ‡∏î‡∏µ! Face Detection ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ\")\n",
    "            else:\n",
    "                print(\"\\n‚ö†Ô∏è  ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Face Detection\")\n",
    "                print(\"üí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏™‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á: {e}\")\n",
    "        print(\"üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:\")\n",
    "        print(\"   1. ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó Jupyter Notebook\")\n",
    "        print(\"   2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥\")\n",
    "        print(\"   3. ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á\")\n",
    "\n",
    "print(\"üìπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á Face Detection ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\")\n",
    "print(\"\\nüí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\")\n",
    "print(\"   ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: run_face_detection_webcam()\")\n",
    "\n",
    "print(\"\\nüî• ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection:\")\n",
    "print(\"   1. ‡∏´‡∏±‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\")\n",
    "print(\"   2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏™‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ\")  \n",
    "print(\"   3. ‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏™‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö\")\n",
    "print(\"   4. ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡∏µ‡∏°‡πà‡∏ß‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\")\n",
    "print(\"   5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö Face Detection:\")\n",
    "print(\"run_face_detection_webcam()\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d029b96",
   "metadata": {},
   "source": [
    "## üéØ ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "### ‚úÖ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏ß‡∏£‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:\n",
    "\n",
    "1. **‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ ‚â• 80%** - ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "2. **‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô Real-time** - ‡πÑ‡∏°‡πà‡∏ä‡πâ‡∏≤ ‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡∏Å\n",
    "3. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏î‡πâ** - ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡πÅ‡∏¢‡∏Å‡πÑ‡∏î‡πâ 3-5 ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå\n",
    "\n",
    "### üîÑ ‡∏´‡∏≤‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏î‡∏µ:\n",
    "\n",
    "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ**\n",
    "- üí° ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ `min_detection_confidence` ‡πÉ‡∏´‡πâ‡∏ï‡πà‡∏≥‡∏•‡∏á (0.3-0.4)\n",
    "- üì∏ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÅ‡∏™‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "- üé• ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "\n",
    "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏ä‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ**\n",
    "- üîß ‡πÉ‡∏ä‡πâ `model_selection=0` (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÉ‡∏Å‡∏•‡πâ)\n",
    "- üìè ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\n",
    "- ‚ö° ‡πÉ‡∏ä‡πâ GPU ‡∏´‡∏≤‡∏Å‡∏°‡∏µ\n",
    "\n",
    "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏°‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥**\n",
    "- ü§ñ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Emotion Recognition\n",
    "- üìä ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Mock data ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Frontend:\n",
    "\n",
    "1. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á face-api.js** ‡πÉ‡∏ô Frontend project\n",
    "2. **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•** ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `public/face-models/`\n",
    "3. **‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô JavaScript Code** ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÉ‡∏ô README.md\n",
    "4. **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô Browser** ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Hand Detection\n",
    "\n",
    "---\n",
    "\n",
    "### üìû ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏µ‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠:\n",
    "\n",
    "- **Person 1 & 2:** ‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Hand Models\n",
    "- **Person 4:** ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÑ‡∏õ Backend/LLM\n",
    "- **‡∏ó‡∏µ‡∏°:** ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö\n",
    "\n",
    "---\n",
    "\n",
    "### üéâ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß:\n",
    "\n",
    "‚úÖ **Face Detection ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ**  \n",
    "‚úÖ **Emotion Analysis ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°**  \n",
    "‚úÖ **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô Real-time ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à**  \n",
    "‚úÖ **‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ú‡∏™‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ Frontend**  \n",
    "\n",
    "**üéä ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡πâ‡∏ß‡∏¢! Face Detection System ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß**\n",
    "\n",
    "---\n",
    "\n",
    "### üí° ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:\n",
    "\n",
    "- **Emotion Recognition** ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ Mock data\n",
    "- **‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á** ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ face-api.js ‡∏´‡∏£‡∏∑‡∏≠ Azure Face API\n",
    "- **MediaPipe** ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Face Detection ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "- **‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û** ‡∏à‡∏∞‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö Browser"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
